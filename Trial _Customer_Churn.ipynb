{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f313bc7-4d66-4cf6-8157-31871122761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f84fd3-0f91-4360-aa95-f8ad5271db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (440833, 11)\n",
      "Shape of X_test: (64374, 11)\n",
      "First 5 rows of X_train:\n",
      "    CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0         2.0  30.0       0    39.0             14.0            5.0   \n",
      "1         3.0  65.0       0    49.0              1.0           10.0   \n",
      "2         4.0  55.0       0    14.0              4.0            6.0   \n",
      "3         5.0  58.0       1    38.0             21.0            7.0   \n",
      "4         6.0  23.0       1    32.0             20.0            5.0   \n",
      "\n",
      "   Payment Delay  Subscription Type  Contract Length  Total Spend  \\\n",
      "0           18.0                  2                0        932.0   \n",
      "1            8.0                  0                1        557.0   \n",
      "2           18.0                  0                2        185.0   \n",
      "3            7.0                  2                1        396.0   \n",
      "4            8.0                  0                1        617.0   \n",
      "\n",
      "   Last Interaction  \n",
      "0              17.0  \n",
      "1               6.0  \n",
      "2               3.0  \n",
      "3              29.0  \n",
      "4              20.0  \n"
     ]
    }
   ],
   "source": [
    "# Load Training & Testing Datasets\n",
    "df_train = pd.read_csv(r\"C:\\Users\\cex\\Desktop\\Data sets\\customerchurn-training.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\cex\\Desktop\\Data sets\\customerchurn-testing.csv\")\n",
    "\n",
    "# Encode Categorical Variables\n",
    "label_encoders = {}\n",
    "for col in df_train.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.transform(df_test[col])\n",
    "    label_encoders[col] = le  # Store for potential deployment use\n",
    "\n",
    "# Define Features & Target\n",
    "X_train = df_train.drop(columns=['Churn'])  # Features\n",
    "y_train = df_train['Churn']  # Target\n",
    "\n",
    "X_test = df_test.drop(columns=['Churn'])  # Features for final evaluation\n",
    "y_test = df_test['Churn']  # Target for final evaluation\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Debugging: Check if data is properly loaded\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"First 5 rows of X_train:\\n\", X_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85287276-3003-4782-ba4e-854676985756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y_train: 1\n",
      "\n",
      "Random Forest Accuracy: 0.49467176189144685\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in target variable\n",
    "print(\"Missing values in y_train:\", y_train.isnull().sum())\n",
    "\n",
    "# Drop rows where target variable is NaN\n",
    "df_train = df_train.dropna(subset=['Churn'])\n",
    "\n",
    "# Define Features & Target again after dropping NaNs\n",
    "X_train = df_train.drop(columns=['Churn'])  \n",
    "y_train = df_train['Churn']\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_scaled, y_train)  # Should work now\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Print accuracy to confirm\n",
    "print(\"\\nRandom Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28021b78-cab8-408f-ba66-1fda65ea18fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in y_train: 0\n",
      "Missing values in y_test: 0\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cex\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:57:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned XGBoost Accuracy: 0.5026408177214403\n",
      "\n",
      "Tuned XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.06      0.10     33881\n",
      "           1       0.49      1.00      0.66     30493\n",
      "\n",
      "    accuracy                           0.50     64374\n",
      "   macro avg       0.74      0.53      0.38     64374\n",
      "weighted avg       0.75      0.50      0.37     64374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in target variable\n",
    "print(\"Missing values in y_train:\", y_train.isnull().sum())\n",
    "print(\"Missing values in y_test:\", y_test.isnull().sum())\n",
    "\n",
    "# Drop NaN values in y_train\n",
    "df_train = df_train.dropna(subset=['Churn'])  \n",
    "\n",
    "# Reassign X_train and y_train after cleaning\n",
    "X_train = df_train.drop(columns=['Churn'])  \n",
    "y_train = df_train['Churn']\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train to an array\n",
    "y_train = y_train.values  # Ensures proper format for training\n",
    "\n",
    "# Define Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  \n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize and Train GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,  \n",
    "    n_jobs=-1  \n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)  # Should work now\n",
    "\n",
    "# Best XGBoost Model After Tuning\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best_xgb = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"\\nTuned XGBoost Accuracy:\", accuracy_score(y_test, y_pred_best_xgb))\n",
    "print(\"\\nTuned XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_best_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8281e1-ff2b-4191-9898-7cfa71f001d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cex\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:58:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking y_pred_best_xgb: [1 1 1 1 1 1 1 1 1 1]\n",
      "Checking y_test: 0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    1\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Churn, dtype: int64\n",
      "\n",
      "Random Forest Accuracy: 0.49467176189144685\n",
      "\n",
      "Tuned XGBoost Accuracy: 0.5026408177214403\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.04      0.08     33881\n",
      "           1       0.48      1.00      0.65     30493\n",
      "\n",
      "    accuracy                           0.49     64374\n",
      "   macro avg       0.74      0.52      0.36     64374\n",
      "weighted avg       0.75      0.49      0.35     64374\n",
      "\n",
      "\n",
      "Tuned XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.06      0.10     33881\n",
      "           1       0.49      1.00      0.66     30493\n",
      "\n",
      "    accuracy                           0.50     64374\n",
      "   macro avg       0.74      0.53      0.38     64374\n",
      "weighted avg       0.75      0.50      0.37     64374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Reduced for speed\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize and Train GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,  # Show progress\n",
    "    n_jobs=-1   # Use all CPU cores\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best XGBoost Model After Tuning\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best_xgb = best_xgb.predict(X_test_scaled)\n",
    "\n",
    "# Debugging: Check Predictions Exist\n",
    "print(\"Checking y_pred_best_xgb:\", y_pred_best_xgb[:10])  # First 10 predictions\n",
    "print(\"Checking y_test:\", y_test[:10])  # First 10 actual labels\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"\\nRandom Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nTuned XGBoost Accuracy:\", accuracy_score(y_test, y_pred_best_xgb))\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nTuned XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_best_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82032a-9f6d-45f7-9429-9d0726d898f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
